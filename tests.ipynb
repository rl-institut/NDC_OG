{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "GRID = 'grid'\n",
    "MG = 'mg'\n",
    "SHS = 'shs'\n",
    "ELECTRIFICATION_OPTIONS = [GRID, MG, SHS]\n",
    "BAU_SCENARIO = 'bau'\n",
    "SE4ALL_SCENARIO = 'uea'\n",
    "SE4ALL_FLEX_SCENARIO = 'se4all_shift'\n",
    "PROG_SCENARIO = 'prog'\n",
    "SCENARIOS = [BAU_SCENARIO, SE4ALL_SCENARIO, PROG_SCENARIO]\n",
    "\n",
    "# Names for display\n",
    "SCENARIOS_DICT = {\n",
    "    BAU_SCENARIO: 'BaU',\n",
    "    SE4ALL_SCENARIO: 'uEA',\n",
    "    PROG_SCENARIO: 'prOG',\n",
    "}\n",
    "\n",
    "ELECTRIFICATION_DICT = {\n",
    "    GRID: 'Grid',\n",
    "    MG: 'Mini Grid',\n",
    "    SHS: 'Solar Home System'\n",
    "}\n",
    "\n",
    "# column names of the exogenous results\n",
    "ENDO_POP_GET = ['endo_pop_get_%s_2030' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "POP_GET = ['pop_get_%s_2030' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "HH_GET = ['hh_get_%s_2030' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "HH_CAP = ['hh_%s_capacity' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "HH_SCN2 = ['hh_cap_scn2_%s_capacity' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "INVEST = ['%s_investment_cost' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "INVEST_CAP = ['tier_capped_%s_investment_cost' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "GHG = ['ghg_%s_cumul' % opt for opt in ELECTRIFICATION_OPTIONS] + ['ghg_no_access_cumul']\n",
    "GHG_ER = ['ghg_%s_ER_cumul' % opt for opt in ELECTRIFICATION_OPTIONS] \\\n",
    "         + ['ghg_no_access_ER_cumul']\n",
    "GHG_CAP = ['tier_capped_ghg_%s_cumul' % opt for opt in ELECTRIFICATION_OPTIONS] \\\n",
    "          + ['tier_capped_ghg_no_access_cumul']\n",
    "GHG_CAP_ER = ['tier_capped_ghg_%s_ER_cumul' % opt for opt in ELECTRIFICATION_OPTIONS] \\\n",
    "             + ['tier_capped_ghg_no_access_ER_cumul']\n",
    "GHG_ALL = GHG + GHG_ER + GHG_CAP + GHG_CAP_ER \\\n",
    "          + ['ghg_tot_cumul', 'tier_capped_ghg_tot_cumul'] \\\n",
    "          + ['ghg_tot_ER_cumul', 'tier_capped_ghg_tot_ER_cumul'] \\\n",
    "    + ['ghg_%s_2030' % opt for opt in ELECTRIFICATION_OPTIONS] \\\n",
    "    + ['tier_capped_ghg_%s_2030' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "EXO_RESULTS = POP_GET + HH_GET + HH_CAP + HH_SCN2 + INVEST + INVEST_CAP + GHG_ALL\n",
    "\n",
    "# source http://www.worldbank.org/content/dam/Worldbank/Topics/Energy%20and%20Extract/\n",
    "# Beyond_Connections_Energy_Access_Redefined_Exec_ESMAP_2015.pdf\n",
    "MIN_TIER_LEVEL = 3\n",
    "MIN_RATED_CAPACITY = {1: 3, 2: 50, 3: 200, 4: 800, 5: 2000}  # index is TIER level [W]\n",
    "MIN_ANNUAL_CONSUMPTION = {1: 4.5, 2: 73, 3: 365, 4: 1250, 5: 3000}  # index is TIER level [kWh/a]\n",
    "RATIO_CAP_CONSUMPTION = {}\n",
    "\n",
    "# Investment Cost Source: Arranz and Worldbank,\n",
    "# BENCHMARKING STUDY OF SOLAR PV MINIGRIDS INVESTMENT COSTS, 2017 (Jabref)\n",
    "# unit is USD per household\n",
    "MEDIAN_INVESTMENT_COST = {1: 742, 2: 1273, 3: 2516, 4: 5277, 5: 5492}\n",
    "\n",
    "# drives for the socio-economic model\n",
    "IMPACT_FACTORS = pd.DataFrame(\n",
    "    {\n",
    "        MG: [3, 13. / 6, 19. / 6, 3.25, 11. / 3],\n",
    "        SHS: [23. / 12, 4.5, 37. / 12, 17. / 6, 41. / 12],\n",
    "        'labels': [\n",
    "            'high_gdp',\n",
    "            'high_mobile_money',\n",
    "            'high_ease_doing_business',\n",
    "            'low_corruption',\n",
    "            'high_grid_weakness'\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "IMPACT_FACTORS = IMPACT_FACTORS.set_index('labels')\n",
    "\n",
    "MENTI_DRIVES = ['gdp', 'mobile_money', 'ease_doing_business', 'corruption', 'weak_grid']\n",
    "\n",
    "# $RT_shift_factors.$P$2\n",
    "WEIGHT_MENTIS = 0.2\n",
    "# -->WEIGHT_GRID = 0.8 ($RT_shift_factors.$O$2)  and  WEIGHT_GRID = 1 - WEIGHT_MENTIS\n",
    "RISE_INDICES = ['rise_%s' % opt for opt in ELECTRIFICATION_OPTIONS]\n",
    "SHIFT_MENTI = ['shift_menti_mg', 'shift_menti_shs']\n",
    "\n",
    "BASIC_ROWS = [\n",
    "    'People share',\n",
    "    'People (k)',\n",
    "    'HH (k)',\n",
    "    'HH cap. (MW)',\n",
    "    'HH cap. (MW) (TIER + 1)',\n",
    "    'Investment MUSD',\n",
    "    'Investment (TIER + 1) MUSD',\n",
    "]\n",
    "# labels of the columns of the result tables\n",
    "LABEL_COLUMNS = ELECTRIFICATION_DICT.copy()\n",
    "# a column for the row labels\n",
    "LABEL_COLUMNS['labels'] = ''\n",
    "LABEL_COLUMNS['total'] = 'Total'\n",
    "BASIC_COLUMNS_ID = ['labels'] + ELECTRIFICATION_OPTIONS + ['total']\n",
    "GHG_COLUMNS_ID = ['labels'] + ELECTRIFICATION_OPTIONS + ['total']\n",
    "COMPARE_COLUMNS_ID = ['labels']\n",
    "for opt in ELECTRIFICATION_OPTIONS + ['total']:\n",
    "    COMPARE_COLUMNS_ID.append(opt)\n",
    "    COMPARE_COLUMNS_ID.append('comp_{}'.format(opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results for a specific country for each scenario\n",
    "from data.data_preparation import compute_ndc_results_from_raw_data\n",
    "iso = 'NGA'\n",
    "\n",
    "for sce in SCENARIOS:\n",
    "    df = compute_ndc_results_from_raw_data(sce, MIN_TIER_LEVEL)\n",
    "    df = df.loc[df.country_iso == iso]\n",
    "    df = df[EXO_RESULTS].transpose()\n",
    "    print(sce)\n",
    "    print(df)\n",
    "    df.to_csv('NDC_results_{}_{}.csv'.format(sce, iso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cumulated results for each scenario\n",
    "from data.data_preparation import compute_ndc_results_from_raw_data, EXO_RESULTS\n",
    "for sce in SCENARIOS:\n",
    "    df = compute_ndc_results_from_raw_data(sce, MIN_TIER_LEVEL)\n",
    "    \n",
    "    df = df[EXO_RESULTS].sum(axis=0)\n",
    "    print(sce)\n",
    "    print(df)\n",
    "    df.to_csv('NDC_results_{}.csv'.format(sce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_preparation import SHS_SALES_VOLUMES, SHS_POWER_CATEGORIES, SHS_AVERAGE_INVESTMENT_COST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHS_SALES_VOLUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHS_AVERAGE_INVESTMENT_COST\n",
    "shs_costs = pd.read_csv('data/shs_power_investment_cost.csv', comment='#')\n",
    "shs_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results for each scenario for tests\n",
    "from data.data_preparation import compute_ndc_results_from_raw_data, EXO_RESULTS\n",
    "for sce in SCENARIOS:\n",
    "    df = compute_ndc_results_from_raw_data(sce, MIN_TIER_LEVEL)\n",
    "    df = df[EXO_RESULTS + ['country', 'country_iso']]\n",
    "    df.to_csv('tests/data/results_test_comparison_{}.csv'.format(sce))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TIER level attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import _find_tier_level\n",
    "\n",
    "for hh_cons in np.array([1, 50, 100, 400, 2000, 5000]):\n",
    "    print(_find_tier_level(hh_cons, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import _slope_capacity_vs_yearly_consumption\n",
    "RATIO_CAP_CONSUMPTION = {}\n",
    "TIER_LEVELS = [1, 2, 3, 4, 5]\n",
    "for tier_lvl in [1, 2, 3, 4]:\n",
    "    RATIO_CAP_CONSUMPTION[tier_lvl] = _slope_capacity_vs_yearly_consumption(tier_lvl)\n",
    "RATIO_CAP_CONSUMPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RATED_CAPACITY = {1: 3, 2: 50, 3: 200, 4: 800, 5: 2000}  # index is TIER level [W]\n",
    "MIN_ANNUAL_CONSUMPTION = {1: 4.5, 2: 73, 3: 365, 4: 1250, 5: 3000}  # index is TIER level [kWh/a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tier_lvl in TIER_LEVELS:\n",
    "    print(MIN_RATED_CAPACITY[tier_lvl] / MIN_ANNUAL_CONSUMPTION[tier_lvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = [MIN_RATED_CAPACITY[i] for i in TIER_LEVELS]\n",
    "df = pd.DataFrame(cap)\n",
    "df[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = [MIN_ANNUAL_CONSUMPTION[i] for i in TIER_LEVELS]\n",
    "df = pd.DataFrame(cons)\n",
    "df[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import IMPACT_FACTORS\n",
    "IMPACT_FACTORS.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for opt in [MG, SHS]:\n",
    "    for input_name in IMPACT_FACTORS.index.to_list():\n",
    "        #print(\"Input('impact-{}-{}-input', 'value'),\".format(opt, input_name.replace('_', '-')))\n",
    "        print('impact_{}_{},'.format(opt, input_name.replace('high', '')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_preparation import compute_ndc_results_from_raw_data\n",
    "SCENARIOS_DATA = {\n",
    "    sce: compute_ndc_results_from_raw_data(sce, MIN_TIER_LEVEL).to_json() for sce in SCENARIOS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = se_df[POP_GET ]\n",
    "a['summe'] = a.sum(axis=1)\n",
    "a['tot'] = se_df['pop_newly_electrified_2030']\n",
    "a['diffe'] = a.tot.values - a.summe.values\n",
    "a.loc[a.diffe > 5e-9]\n",
    "a[POP_GET] = a[POP_GET].div(se_df.pop_newly_electrified_2030, axis=0)\n",
    "a['summe'] = a[POP_GET].sum(axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_bau = pd.read_csv('data/xls_bau.csv', float_precision='high')\n",
    "xls_se = pd.read_csv('data/xls_se.csv', float_precision='high')\n",
    "xls_prog = pd.read_csv('data/xls_prog.csv', float_precision='high')\n",
    "\n",
    "invest_bau = pd.read_csv('data/invest_bau.csv', float_precision='high')\n",
    "invest_se = pd.read_csv('data/invest_se.csv', float_precision='high')\n",
    "invest_prog = pd.read_csv('data/invest_prog.csv', float_precision='high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RISE new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "xls_se = pd.read_csv('NDC_full_results_old_rise_model_se4all.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = EXO_RESULTS\n",
    "\n",
    "df_diff = xls_se[COMP_COLS] - se_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=1):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff[INVEST].loc[l]\n",
    "\n",
    "df_diff[COMP_COLS].to_csv('se4all_old_model_minus_updated.csv')\n",
    "xls_se[COMP_COLS].to_csv('se4all_old_model.csv')\n",
    "se_df[COMP_COLS].to_csv('se4all_updated_model.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Exogenous results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bau_df = pd.read_json(SCENARIOS_DATA[BAU_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "xls_bau = pd.read_csv('data/xls_bau.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = POP_GET + HH_GET + HH_CAP + HH_SCN2\n",
    "\n",
    "df_diff = xls_bau[COMP_COLS] - bau_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=0.2):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE4ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "xls_se = pd.read_csv('data/xls_uea.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = POP_GET + HH_GET + HH_CAP + HH_SCN2\n",
    "\n",
    "df_diff = xls_se[COMP_COLS] - se_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=0.001):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_prog = pd.read_csv('data/xls_prog.csv', float_precision='high')\n",
    "prog_df = pd.read_json(SCENARIOS_DATA[PROG_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "\n",
    "COMP_COLS = POP_GET + HH_GET + HH_CAP + HH_SCN2\n",
    "\n",
    "df_diff = xls_prog[COMP_COLS] - prog_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=0.2):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GHG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bau_df = pd.read_json(SCENARIOS_DATA[BAU_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "ghg_bau = pd.read_csv('data/ghg_bau.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = GHG + GHG_CAP\n",
    "\n",
    "df_diff = ghg_bau[COMP_COLS] - bau_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=40):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "ghg_se = pd.read_csv('data/ghg_se.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = GHG + GHG_CAP\n",
    "\n",
    "df_diff = ghg_se[COMP_COLS] - se_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=40):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved from BaU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bau_df = pd.read_json(SCENARIOS_DATA[BAU_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "se_df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = GHG + GHG_CAP\n",
    "\n",
    "saved_se_df = bau_df[COMP_COLS] - se_df[COMP_COLS]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_df = pd.read_json(SCENARIOS_DATA[PROG_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "ghg_prog = pd.read_csv('data/ghg_prog.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = GHG + GHG_CAP\n",
    "\n",
    "df_diff = ghg_prog[COMP_COLS] - prog_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=40):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Investment cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bau_df = pd.read_json(SCENARIOS_DATA[BAU_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "invest_bau = pd.read_csv('data/invest_bau.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = INVEST + INVEST_CAP\n",
    "\n",
    "df_diff = invest_bau[COMP_COLS] - bau_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=40):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SE4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "invest_se = pd.read_csv('data/invest_se.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = INVEST + INVEST_CAP\n",
    "\n",
    "df_diff = invest_se[COMP_COLS] - se_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=20):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_df = pd.read_json(SCENARIOS_DATA[PROG_SCENARIO]).set_index('country_iso').sort_index(ascending=True)\n",
    "invest_prog = pd.read_csv('data/invest_prog.csv', float_precision='high').set_index('country_iso').sort_index(ascending=True)\n",
    "\n",
    "COMP_COLS = INVEST + INVEST_CAP\n",
    "\n",
    "df_diff = invest_prog[COMP_COLS] - prog_df[COMP_COLS]\n",
    "\n",
    "def highlight_mismatch(col, eps=40):\n",
    "    return df_diff.loc[np.abs(df_diff[col]) > eps]\n",
    "\n",
    "l = []\n",
    "for col in COMP_COLS:\n",
    "    temp = highlight_mismatch(col).index.to_list()\n",
    "    if temp:\n",
    "        print('problems with ', col, temp)\n",
    "        print(len(temp))\n",
    "    l = l + temp\n",
    "len(set(l))\n",
    "l = list(set(l))\n",
    "df_diff.loc[l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rise shifts for electrification option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$i \\in $ (grid, mg, shs)\n",
    "\n",
    "$N_i$ : population getting option $i$ in 2030\n",
    "\n",
    "$R_i$ : RISE score for the option $i$\n",
    "\n",
    "$\\delta_{ij} = R_i - R_j$\n",
    "\n",
    "$\\Delta_i = \\frac{\\sum_j \\delta_ij}{\\sum R_k} $\n",
    "\n",
    "$\\Delta N_i = \\Delta_i (\\sum_j N_j)$\n",
    "\n",
    "Constraint is that $\\sum_j \\Delta N_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarah PF Model\n",
    "$R_i \\neq 0$, $\\forall i$\n",
    "\n",
    "$N_i - \\Delta N_i < 0$,  for some $i$\n",
    "\n",
    "if $N_i - \\Delta N_i < 0$,  for one $i$ ([90,10,45], [30, 40, 30]), then we take $\\Delta N_i = N_i \\Delta_i < 0$ for this $i$ and we split this value between the $j$ for which $N_j - \\Delta N_j > 0$, with the weight $\\frac{R_j}{\\sum_{k \\neq i} R_k}$. That way we don't over-penalize\n",
    "\n",
    "if $N_i - \\Delta N_i < 0$,  for two $i$ ([90,10,15], [30, 40, 5]), then we take $\\Delta N_i = N_i \\Delta_i < 0$ for these $i$ and we add their  absolute sum to the $j$ for which $N_j - \\Delta N_j > 0$. That way we don't over-penalize\n",
    "\n",
    "\n",
    "The case ([90,10,45], [30, 700, 30]) penalize the R3 = 45 more than the R2=20 which is wrong, this is a limiting case to explore, maybe the solution would be to still penalize according to the initial $\\Delta_{ij}$ (ie if $\\Delta_{ij}$ < 0), then one must nevertheless be penalized, although it might be small and not have the penalty of the $i$ for which $N_i - \\Delta N_i < 0$ redistributed equally among the remaining $j$\n",
    "\n",
    "Maybe we want to cap the maximum value that can be given to a $N_i$ to be no larger than $N_i \\Delta_i$, maybe not ?\n",
    "between [90,5,55], [30, 600, 30] and [90,1,55], [30, 600, 30], the reward is dispoportionate in favor of R1 in first case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "def compute_rise_shifts_spfm(rise, pop_get, opt, flag=''):\n",
    "    df = pd.DataFrame(\n",
    "        data=[rise, pop_get, [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
    "        columns=ELECTRIFICATION_OPTIONS)\n",
    "\n",
    "    please_print = True\n",
    "\n",
    "    if df.iloc[0].sum() == 0:\n",
    "        df.iloc[6] = df.iloc[0]\n",
    "    else:\n",
    "        df.iloc[2] = df.iloc[1] / df.iloc[1].sum()\n",
    "        df.iloc[3, 0] = (df.iloc[0].grid - df.iloc[0].mg) + (df.iloc[0].grid - df.iloc[0].shs)\n",
    "        df.iloc[3, 1] = (df.iloc[0].mg - df.iloc[0].grid) + (df.iloc[0].mg - df.iloc[0].shs)\n",
    "        df.iloc[3, 2] = (df.iloc[0].shs - df.iloc[0].mg) + (df.iloc[0].shs - df.iloc[0].grid)\n",
    "\n",
    "        df.iloc[3] = df.iloc[3] / df.iloc[0].sum()\n",
    "\n",
    "        for j in range(3):\n",
    "            df.iloc[4, j] = df.iloc[1].sum() * df.iloc[3, j]\n",
    "            if df.iloc[1, j] != 0:\n",
    "                df.iloc[5, j] = df.iloc[4, j] / df.iloc[1, j]\n",
    "            else:\n",
    "                df.iloc[5, j] = np.nan\n",
    "\n",
    "        df.iloc[6] = df.iloc[1] + df.iloc[4]\n",
    "        diff = df.iloc[6].values\n",
    "        # logging.debug(diff)\n",
    "        diff = diff[diff < 0]\n",
    "        if len(diff) == 2:\n",
    "            logging.debug('There are two differences smaller than 0')\n",
    "            diff = df.iloc[6].values\n",
    "            diff = diff[diff > 0]\n",
    "            idx = df.iloc[6].to_list().index(diff[0])\n",
    "\n",
    "            eps = 0\n",
    "            for i in range(3):\n",
    "                if i != idx:\n",
    "                    df.iloc[6, i] = df.iloc[1, i] * df.iloc[3, i]\n",
    "                    eps = eps + np.abs(df.iloc[6, i])\n",
    "            df.iloc[6, idx] = eps\n",
    "\n",
    "        elif len(diff) == 1:\n",
    "            logging.debug('one difference is smaller than 0')\n",
    "            idx = df.iloc[6].to_list().index(diff[0])\n",
    "            norm = 0\n",
    "            idx2 = None\n",
    "            # find out if there is another penalized case\n",
    "            for i in range(3):\n",
    "                if i != idx:\n",
    "                    if df.iloc[3, i] < 0:\n",
    "                        idx2 = i\n",
    "                    norm = norm + df.iloc[3, i]\n",
    "\n",
    "            if idx2 is None:\n",
    "                logging.debug('the difference will be fully split between the two other case')\n",
    "                # we take N_i Delta_i away from N_i and split it amongst the remaining\n",
    "                # options\n",
    "                eps = df.iloc[1, idx] * df.iloc[3, idx]\n",
    "                for i in range(3):\n",
    "                    if i == idx:\n",
    "                        df.iloc[6, i] = eps\n",
    "                    else:\n",
    "                        # weight Delta_i / sum(Delta_j, with j !=idx)\n",
    "                        df.iloc[6, i] = np.abs(eps) * df.iloc[3, i] / norm\n",
    "            else:\n",
    "                logging.debug('one of the remaining should have a penalty')\n",
    "\n",
    "                over_penalty = []\n",
    "                for j in range(3):\n",
    "                    if df.iloc[4, j] <= df.iloc[1, j] * df.iloc[3, j]:\n",
    "                        over_penalty.append(j)\n",
    "                        df.iloc[6, j] = df.iloc[1, j] * df.iloc[3, j]\n",
    "                idx_not_penalised = list(set(range(3)) - set(over_penalty))[0]\n",
    "\n",
    "                df.iloc[6, idx_not_penalised] = np.abs(df.iloc[6, over_penalty].sum())\n",
    "\n",
    "                # eps = df.iloc[1, idx] * df.iloc[3, idx]\n",
    "\n",
    "                ## this one cannot be larger that its population\n",
    "                # df.iloc[6, idx] = eps\n",
    "                ## this one becomes a part of the population from above, which compensates\n",
    "                ## a bit the penalty\n",
    "                # df.iloc[6, idx2] = df.iloc[4, idx2] + np.abs(eps) * df.iloc[\n",
    "                #    0, idx2] / norm\n",
    "                ## the highest score receives the penalty\n",
    "                # for i in range(3):\n",
    "                #    if i != idx and i != idx2:\n",
    "                #        #logging.debug(i)\n",
    "                #        df.iloc[6, i] = np.abs(df.iloc[4, idx2]) + np.abs(eps) * \\\n",
    "                #                        df.iloc[0, i] / norm\n",
    "        elif len(df) == 3:\n",
    "            logging.debug('error, all differences are negative')\n",
    "        else:\n",
    "            logging.debug('no difference is smaller than 0')\n",
    "\n",
    "            # check if any Delta_i < 0\n",
    "            diff = df.iloc[3].values\n",
    "            diff = diff[diff < 0]\n",
    "            if len(diff) == 1:\n",
    "                logging.debug('Only one should be penalized')\n",
    "                logging.debug('The difference will be fully split between the two other case')\n",
    "                idx = df.iloc[3].to_list().index(diff[0])\n",
    "                norm = 0\n",
    "                for i in range(3):\n",
    "                    if i != idx:\n",
    "                        # the sum of the Delta_i of each non-penalized\n",
    "                        norm = norm + df.iloc[3, i]\n",
    "\n",
    "                eps = df.iloc[1, idx] * df.iloc[3, idx]\n",
    "                for i in range(3):\n",
    "                    if i == idx:\n",
    "                        df.iloc[6, i] = eps\n",
    "                    else:\n",
    "                        # weight Delta_i / sum(Delta_j, with j !=idx)\n",
    "                        df.iloc[6, i] = np.abs(eps) * df.iloc[3, i] / norm\n",
    "\n",
    "                        # ----\n",
    "            elif len(diff) == 2:\n",
    "                over_penalty = []\n",
    "                for j in range(3):\n",
    "                    if df.iloc[4, j] <= df.iloc[1, j] * df.iloc[3, j]:\n",
    "                        over_penalty.append(j)\n",
    "                        df.iloc[6, j] = df.iloc[1, j] * df.iloc[3, j]\n",
    "                idx_not_penalised = list(set(range(3)) - set(over_penalty))[0]\n",
    "\n",
    "                df.iloc[6, idx_not_penalised] = np.abs(df.iloc[6, over_penalty].sum())\n",
    "\n",
    "                # logging.debug(over_penalty)\n",
    "                logging.debug('Two should be penalized')\n",
    "            elif len(diff) == 3:\n",
    "                logging.debug('error, all deltas are negative')\n",
    "            else:\n",
    "                # case when all RISE are equal\n",
    "                logging.debug('error, all deltas are positive or zero')\n",
    "                df.iloc[6] = df.iloc[4]\n",
    "                please_print = True\n",
    "\n",
    "        df.iloc[7] = df.iloc[6] + df.iloc[1]\n",
    "        for i in range(3):\n",
    "            if df.iloc[1, i] != 0:\n",
    "                df.iloc[5, i] = df.iloc[6, i] / df.iloc[1, i]\n",
    "            else:\n",
    "                df.iloc[5, i] = np.nan\n",
    "\n",
    "    if df.iloc[6].sum() > 1e-6:\n",
    "        logging.debug(\n",
    "            'Error ({}): the sum of the shifts ({}) is not equal to zero!'.format(\n",
    "                flag,\n",
    "                df.iloc[6].sum(),\n",
    "            )\n",
    "        )\n",
    "        please_print = True\n",
    "\n",
    "    if please_print:\n",
    "        logging.debug(flag)\n",
    "        df['sum'] = df.sum(axis=1)\n",
    "\n",
    "        df['labels'] = ['R_i', 'N_i', 'n_i', 'Delta_i', 'Delta N_i', 'Delta N_i / N_i (case 2)',\n",
    "                        'Delta N_i (case 2)', 'Delta N_i + N_i (case 2)']\n",
    "        # logging.debug(df)\n",
    "        # logging.debug()\n",
    "        # logging.debug()\n",
    "    return df  # df.iloc[6, ELECTRIFICATION_OPTIONS.index(opt)]\n",
    "\n",
    "vals=np.arange(1,100,1)\n",
    "#vals=[13]\n",
    "y = {'grid_vs_x':[], 'mg_vs_x': [], 'shs_vs_x': []}\n",
    "for x in vals:\n",
    "    pass\n",
    "    #a = compute_rise_shifts([16.67,  35,  x], [3.9198e+07,  1.75457e+07,  4.09613e+07], 0)\n",
    "    # [16.67,  35,  22.22]\n",
    "    # [7.62143e+06,  5.86826e+07,  3.1401e+07]\n",
    "    #y['grid_vs_x'].append(a.iloc[7, 0])\n",
    "    #y['mg_vs_x'].append(a.iloc[7, 1])\n",
    "    #y['shs_vs_x'].append(a.iloc[7, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Philipp Rise score model\n",
    "\n",
    "### Inputs\n",
    "\n",
    "$i \\in $ (grid, mg, shs)\n",
    "\n",
    "$N_i$ : predicted population getting option $i$ in 2030\n",
    "\n",
    "$R_i$ : RISE score for the option $i$\n",
    "\n",
    "### Definitions\n",
    "\n",
    "$\\delta_{ij} = R_i - R_j$\n",
    "\n",
    "$\\Delta N_i$ : what gets added or removed from $N_i$\n",
    "\n",
    "$\\Delta N_{ij}$ : what is taken from $N_i$ and is transferred to $N_j$\n",
    "\n",
    "Constraint is that $\\sum_j \\Delta N_j$\n",
    "\n",
    "### Calculation of $\\Delta N_i$ in case $\\delta_{ij} \\neq 0$ $\\forall i,j$\n",
    "\n",
    "Find the minimum RISE score and compute the penalty:\n",
    "\n",
    "$R_{n} = \\min(\\lbrace R_i \\rbrace)$\n",
    "\n",
    "$\\Delta_n = (\\max(\\lbrace R_i \\rbrace) - R_k) / 100$\n",
    "\n",
    "$\\Delta N_n = - N_n \\Delta_n$\n",
    "\n",
    "$\\Delta N_{ni} = |\\Delta N_n| \\frac{\\delta_{in}}{\\sum_{j}\\delta_{jn}}$ $\\forall i \\neq n$\n",
    "\n",
    "Then we consider the set $\\lbrace R_i \\rbrace_{i \\neq n}$, i.e the next minium score, and compute the penalty:\n",
    "\n",
    "$R_{m} = \\max(\\lbrace R_i \\rbrace_{i \\neq n})$ (then index $p$ for the last index)\n",
    "\n",
    "$\\Delta N_{pm} =  N_p \\frac{\\delta_{mp}}{100}$\n",
    "\n",
    "$\\Delta N_{p} = \\Delta N_{np} - \\Delta N_{pm}$\n",
    "\n",
    "$\\Delta N_{m} = \\Delta N_{nm} + \\Delta N_{pm}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rise_shifts_philipp_model(rise, pop_get, opt, flag=''):\n",
    "    df = pd.DataFrame(\n",
    "        data=[rise, pop_get, [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
    "        columns=ELECTRIFICATION_OPTIONS)\n",
    "\n",
    "    n = ELECTRIFICATION_OPTIONS.index(df.iloc[0].idxmin())\n",
    "    R_n = df.iloc[0].min() \n",
    "    \n",
    "    m = ELECTRIFICATION_OPTIONS.index(df.iloc[0].idxmax())\n",
    "    R_m = df.iloc[0].max()\n",
    "    \n",
    "    p = list(set(range(3)) - set([m,n]))[0]\n",
    "    R_p = df.iloc[0, p]\n",
    "    \n",
    "    if R_n == R_p and R_p == R_m:\n",
    "        df.iloc[4] = 0\n",
    "    else:\n",
    "    \n",
    "        # calulate n_i\n",
    "        df.iloc[2] = df.iloc[1]/df.iloc[1].sum()\n",
    "\n",
    "        Delta_n = (R_m - R_n)/(100)\n",
    "\n",
    "        df.iloc[4, n] = - df.iloc[1, n] * Delta_n \n",
    "\n",
    "        norm = 0\n",
    "        for j in [m, p]:\n",
    "            delta_jn = (df.iloc[0, j] - df.iloc[0, n])\n",
    "            norm = norm + delta_jn\n",
    "            df.iloc[4, j] = np.abs(df.iloc[4, n]) * delta_jn \n",
    "\n",
    "        df.iloc[4, [m, p]] = df.iloc[4, [m, p]] / norm\n",
    "\n",
    "        #--------------------------------------------------------\n",
    "\n",
    "        DeltaN_pm = df.iloc[1, p] * (R_m - R_p) / (100)\n",
    "\n",
    "        df.iloc[4, p] = df.iloc[4, p] - DeltaN_pm\n",
    "        df.iloc[4, m] = df.iloc[4, m] + DeltaN_pm\n",
    "\n",
    "    df.iloc[7] = df.iloc[4] + df.iloc[1]\n",
    "    for i in range(3):\n",
    "        df.iloc[5, i] = df.iloc[4, i] / df.iloc[1, i]\n",
    "\n",
    "    df['sum'] = df.sum(axis=1)\n",
    "\n",
    "    df['labels'] = ['R_i', 'N_i', 'n_i', '', 'Delta N_i', 'Delta N_i / N_i',\n",
    "                        '', 'Delta N_i + N_i']\n",
    "\n",
    "    if df.iloc[4, 3] > 1e-6:\n",
    "        logging.error(\n",
    "            'Error ({}): the sum of the shifts ({}) is not equal to zero!'.format(\n",
    "                flag,\n",
    "                df.iloc[6].sum(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return df\n",
    "    #return df.iloc[6, ELECTRIFICATION_OPTIONS.index(opt)]\n",
    "\n",
    "df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso')\n",
    "  \n",
    "# BDI [1.378121e+07, 2.418979e+05, 1.958563e+05]\n",
    "a = compute_rise_shifts_philipp_model([20, 50, 50], [1e+07, 1e+05, 1e+05], 0)\n",
    "# [16.67,  35,  22.22]\n",
    "# [7.62143e+06,  5.86826e+07,  3.1401e+07]\n",
    "df[ENDO_POP_GET]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = {'sarah_pf_model': {}, 'philipp_model': {}}\n",
    "\n",
    "models = {'sarah_pf_model': compute_rise_shifts, 'philipp_model': compute_rise_shifts_philipp_model}\n",
    "          \n",
    "folder = {'sarah_pf_model': 'access_rise_model', 'philipp_model': 'access_rise_philipp_model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take picture of changing the values of one RISE at the time for each electrification option and each country\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def produce_fom(model_id):\n",
    "    rise_shift_model = models[model_id]\n",
    "    df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso')\n",
    "    for iso in df.index:\n",
    "        print(iso)\n",
    "        endo = df.loc[iso, ENDO_POP_GET].values\n",
    "        rise = df.loc[iso, RISE_INDICES].values\n",
    "        vals=np.arange(0,101,1)\n",
    "        y_vals[model_id][iso] = {}\n",
    "        for i, opt in enumerate(ELECTRIFICATION_OPTIONS):\n",
    "            #vals=[13]\n",
    "            rises = np.vstack([rise for i in vals])\n",
    "            rises[:, i] = vals\n",
    "            y = []\n",
    "            for r in rises:\n",
    "                a = rise_shift_model(r, endo, 0, iso)\n",
    "                y.append(a.iloc[7,0:3].values)\n",
    "            y = np.vstack(y)\n",
    "            \n",
    "            y_vals[model_id][iso][opt] = y\n",
    "            \n",
    "            for j, y_i in enumerate(np.transpose(y)):\n",
    "                opt2 = ELECTRIFICATION_OPTIONS[j]\n",
    "                plt.plot(vals,y_i, label='%s_vary_%s' % (opt2, opt))\n",
    "            plt.plot(vals, y.sum(axis=1))\n",
    "            plt.xlabel('RISE-%s' %opt)\n",
    "            plt.ylabel('Pop')\n",
    "            plt.title('Rise = %s -- %s -- n=%s'%(str(list(rise)), iso, ['%.2f' % i  for i in endo/endo.sum()]))\n",
    "            plt.legend()\n",
    "            plt.savefig('%s/%s_vary_%s.png'%(folder[model_id], iso, opt))\n",
    "            plt.clf()\n",
    "            \n",
    "model_ids = ['philipp_model', 'sarah_pf_model']\n",
    "\n",
    "for model_id in model_ids:\n",
    "    produce_fom(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plots of the model comparison in compare_models folder\n",
    "\n",
    "df = pd.read_json(SCENARIOS_DATA[SE4ALL_SCENARIO]).set_index('country_iso')\n",
    "vals=np.arange(0,101,1)\n",
    "colors = ['#7030a0', '#5b9bd5', '#ed7d31']\n",
    "model_ids = ['philipp_model', 'sarah_pf_model']\n",
    "\n",
    "for iso in df.index:\n",
    "    print(iso)\n",
    "    endo = df.loc[iso, ENDO_POP_GET].values\n",
    "    rise = df.loc[iso, RISE_INDICES].values\n",
    "    for i, opt in enumerate(ELECTRIFICATION_OPTIONS):\n",
    "        for sg, model_id, model_short in zip(['-','--'], model_ids, ['pm', 'spfm']):\n",
    "            y = y_vals[model_id][iso][opt]\n",
    "            for j, y_i in enumerate(np.transpose(y)):\n",
    "                opt2 = ELECTRIFICATION_OPTIONS[j]\n",
    "                plt.plot(vals,y_i, sg, color=colors[j], label='%s_%s_vary_%s' % (model_short, opt2, opt))\n",
    "        #plt.plot(vals, y.sum(axis=1))\n",
    "        plt.xlabel('RISE-%s' %opt)\n",
    "        plt.ylabel('Pop')\n",
    "        plt.title('Rise = %s -- %s -- n=%s'%(str(list(rise)), iso, ['%.2f' % i  for i in endo/endo.sum()]))\n",
    "        plt.legend()\n",
    "        plt.savefig('%s/%s_vary_%s.png'%('compare_models', iso, opt))\n",
    "        plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
